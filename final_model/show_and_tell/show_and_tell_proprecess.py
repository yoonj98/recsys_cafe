# -*- coding: utf-8 -*-
"""show_and_tell_proprecess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SVEuoI16BsoQNpo8TllUlhJ3ynNb-C8v
"""


#!pip install git+https://github.com/naver/kor2vec.git 로컬 환경에서 따로 설치해주세요

# 라이브러리 import
import pandas as pd
import os

from kor2vec import Kor2Vec # Kor2Vec import
import torch
from torch.utils.data import Dataset, DataLoader
from torch import nn
from torchvision import transforms
import torchvision.datasets as datasets
from PIL import Image
import torchvision.models as models # 임베딩 모델
import torchvision
import torch.optim as optim
import matplotlib.pyplot as plt
from keras.preprocessing.image import load_img,img_to_array
import ast

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)


review = pd.read_csv('/content/drive/MyDrive/14,15 추천컨퍼런스/final_model_file/final_df_link.csv', encoding='UTF-8')
img_dir= '/content/drive/MyDrive/14,15 추천컨퍼런스/img_final'
model_dir = "/content/drive/MyDrive/14,15 추천컨퍼런스/"
kor_vec_name= "embedding_final_1"

transform = transforms.Compose(
    [transforms.ToTensor(), # 텐서로 변형
     transforms.Resize(224), # 사이즈 조절
     transforms.CenterCrop(224), # 가로와 세로 중 안 맞는 곳 자르기
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

# kor2vec_hyperparameter 조정
embed_size_tune = 64
batch_size_tune = 64
seq_length = 20



  # 총 사진수 7925,  train = 6340, test = 1585 정도
class preprocess(Dataset):
  def to_list(x):
    return ast.literal_eval(x)

  def str_(x):
    k=','.join(x)
    return k

  def max_len(x):
    return len(x)

  def split_(x):
    return x.split(' ')

  def str1(x):
    k=' '.join(x)
    return k

  # review_token 전처리

  review['summary_text']=review['summary_text'].apply(split_)
  review['summary_text']=review['summary_text'].apply(str_)
  review['summary_text']=review['summary_text'].apply(to_list)
  review['summary_text']=review['summary_text'].apply(str1)


  if kor_vec_name not in os.listdir(model_dir):

    # 리뷰 데이터를 사용해 임베딩을 학습 실시

    rev = pd.Series("<sos> " + review['summary_text']+" <end>")
    rev.to_csv(model_dir+"summary_text_corpus.csv")


    kor2vec = Kor2Vec(embed_size=embed_size_tune) # embed_size : 임베딩 벡터의 2번째 차원(차원 수)
    """
    train([텍스트 데이터 파일 - 위에서 저장, 모델 저장 위치, 학습 배치 사이즈])
    """
    kor2vec.train(model_dir+"summary_text_corpus.csv", 'model.kor2vec', batch_size=batch_size_tune) # 임베딩 실시 (학습)
    kor2vec.save(model_dir+ kor_vec_name)  # 임베딩 모델 저장




class CaptionDataset(Dataset):
    """
    root_dir : 이미지 파일이 있는 경로
    captions_file : 이미지 제목-리뷰가 포함된 데이터프레임
    transform : 이미지를 텐서로 변환할 때 transform (optional)
    """
    def __init__(self, img_dir, caption_df, transform=None):
        self.root_dir = img_dir
        self.transform = transform
        self.df = caption_df
        
        self.imgs = self.df['imgname_123'] # 이미지 파일 경로
        self.captions = self.df["summary_text"] # 리뷰 데이터
        self.kor2vec = Kor2Vec.load(model_dir+ kor_vec_name) # Kor2Vec 로드
        
    
    def __len__(self):
        return len(self.df)
    
    # 이미지, 텍스트를 불러 오는 메소드
    # transform을 선언하면 임베딩 벡터와 1개 배치로 반환하며, 선언하지 않으면 이미지와 스트링 형태의 캡션을 반환합니다.
    def __getitem__(self,idx):
        caption = self.captions[idx] # target caption
        
        img_name = self.imgs[idx] # 이미지 이름 파일 불러오기
        img_location = os.path.join(self.root_dir,img_name) # 실제로 이미지 오픈
        img = Image.open(img_location).convert("RGB")
        
        # transform이 있다면 실시 후 배치화(1 차원 추가)
        if self.transform is not None:
          img = self.transform(img)
          # 정답 임베딩 데이터 
          caption = self.kor2vec.embedding(caption, seq_len=seq_length)

        return img, caption


reveiw_train_data = CaptionDataset(img_dir, review, transform=transform)

img, rev = reveiw_train_data[0]

print(f"img shape : {img.shape}") # ([1, 3, 224, 224]) - [배치, 채널, 가로, 세로]
print(f"rev : {rev.shape}") # ([15, 1000]) - [seq_len, hidden_size]
review_train_dataloader = DataLoader(reveiw_train_data, batch_size=batch_size_tune, shuffle=True)