# -*- coding: utf-8 -*-
"""show_and_tell_proprecess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SVEuoI16BsoQNpo8TllUlhJ3ynNb-C8v
"""

from show_and_tell_embedding import *
from show_and_tell_model import *
from show_and_tell_train import *
from sklearn.metrics.pairwise import euclidean_distances
import sys
import argparse

tag_dir_loc="/content/drive/MyDrive/14,15 추천컨퍼런스/tag"

sys.path.append(tag_dir_loc)
from tag_mobilenet import *
from tag_dataloader import *


location = '/content/drive/MyDrive/14,15 추천컨퍼런스/'
concat_pickle= 'tag_review_embeddings_0709.pickle'
df = pd.read_csv(location+'final_model_file/final_df_link.csv')

transform = transforms.Compose(
  [transforms.ToTensor(), # 텐서로 변형
    transforms.Resize(224), # 사이즈 조절
    transforms.CenterCrop(224), # 가로와 세로 중 안 맞는 곳 자르기
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])



if concat_pickle not in os.listdir(location+py_dir): #임베딩 파일 없을 경우 생성 후 저장

  with open(location+'final_embeddings_shuffle0707_epoch10.pickle', 'rb') as f:
    tag_embed_list=pickle.load(f)
                

  with open(model_dir+py_dir+embedding_dir, 'rb') as z:
    embed_list = pickle.load(z)


  tag_numpy=np.squeeze(np.array(tag_embed_list))
  review_numpy=np.squeeze(np.array(embed_list))
  final_embedding=np.concatenate((tag_numpy,review_numpy), axis=1)

  with open(location+concat_pickle, 'wb') as f:
      pickle.dump(final_embedding, f, pickle.HIGHEST_PROTOCOL)


def classification():
  model = SuperLightMobileNet(5).to(device)
  model.load_state_dict(torch.load(location+'final_model_file/최종_0706_emb_total_model_light9_0.001_10.pth', map_location=device))
  model.eval()  
  return model

def caption():
  model = Net()
  model.to(device)
  model.load_state_dict(torch.load(location+'final_model_file/show_and_tell_final.pt', map_location=device))
  return model

def image_plus(df, img_dir, img_name):


  if df["cafe_image_name"].isin([img_name]).any():

    target_idx=df[df["cafe_image_name"]==img_name].index.to_list()[0]

    with open(location+'tag_review_embeddings_0710.pickle', 'rb') as f:
        tag_review_embeddings = pickle.load(f)

    dist_mtx = euclidean_distances(tag_review_embeddings,tag_review_embeddings)

    plt.imshow(Image.open(img_dir+img_name))
    plt.show()
    # 가장 가까운 것의 인덱스를 제공해준다
    # ex target_idx가 200이라면, 첫 인덱스는 200

    close_list = dist_mtx[target_idx].argsort()[1:6]

    print("가장 가까운 이미지")
    print("======================")
    # target을 포함해 target과 가장 가까운 것 10개
    for i, idx in enumerate(close_list):
        img, rev = reveiw_train_data[idx]
        print(f"{i}, {rev}, distance : {dist_mtx[target_idx][idx]}")
        plt.imshow(img)
        plt.show()

  else:
    transform = transforms.Compose(
      [transforms.ToTensor(), # 텐서로 변형
      transforms.Resize(224), # 사이즈 조절
      transforms.CenterCrop(224), # 가로와 세로 중 안 맞는 곳 자르기
      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    
    # image 사이즈 변경
    #image=Image.open(img_dir)
    img = Image.open(img_dir+img_name).convert("RGB")
    img = transform(img)
    img = img.unsqueeze(0)

    # review embedding
    img = img.to(device)
    review_embed = show_and_tell_model.give_embedding(img).cpu().detach().numpy().reshape(-1, 64)


    # tag embedding
    tag_embed = mobile_net_model.give_embedding(img).cpu().detach().numpy()

    # finale embedding
    final_embed = np.concatenate((tag_embed, review_embed), axis=1)

    # tag + review 임베딩 로드
    with open(location+'tag_review_embeddings_0710.pickle', 'rb') as f:
        tag_review_embeddings = pickle.load(f)
    
    # 최종 embedding concat
    final_embedding = np.concatenate((tag_review_embeddings, final_embed), axis=0)

    #거리 계산
    dist_mtx = euclidean_distances(final_embedding,final_embedding)


    plt.imshow(Image.open(img_dir+img_name))
    plt.show()
    target_idx = len(final_embedding)-1

    # 가장 가까운 것의 인덱스를 제공해준다
    # ex target_idx가 200이라면, 첫 인덱스는 200
    close_list = dist_mtx[target_idx].argsort()[1:6]

    print("가장 가까운 이미지")
    print("======================")
    # target을 포함해 target과 가장 가까운 것 10개
    for i, idx in enumerate(close_list):
        img, rev = reveiw_train_data[idx]
        print(f"{i}, {rev}, distance : {dist_mtx[target_idx][idx]}")
        plt.imshow(img)
        plt.show()

if __name__ == "__main__":



  parser = argparse.ArgumentParser(description='사진경로를 입력해주세요')
  parser.add_argument('--location', type=str, default="/content/drive/MyDrive/14,15 추천컨퍼런스/", help='사진 경로')
  parser.add_argument('--img_name', type=str, default='테스트_힙한카페.jpg',  help='사진파일명')
  args = parser.parse_args()


  reveiw_train_data = CaptionDataset(location+'img_final', df, transform=None)

  mobile_net_model = classification()
  show_and_tell_model = caption()
  image_plus(df,args.location, args.img_name)
  #image_plus(df, location, img_name)



